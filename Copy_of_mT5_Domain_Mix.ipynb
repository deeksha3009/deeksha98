{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deeksha3009/deeksha98/blob/master/Copy_of_mT5_Domain_Mix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementation of language translation for Hindi to Kannada\n",
        "\n",
        "This was implemented using mT5 model for OPUS dataset"
      ],
      "metadata": {
        "id": "02e7Eq_OZnsZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vdbAkdKeRoO"
      },
      "outputs": [],
      "source": [
        "! pip install datasets sacrebleu transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRuCj12ejMmw"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datasets\n",
        "import torch\n",
        "import transformers\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, MT5Tokenizer, MT5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_metric\n",
        "from sacrebleu import corpus_bleu\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj2xIzyBeoii"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the OPUS NLLB dataset containing data from Meta AI\n"
      ],
      "metadata": {
        "id": "aEawcAg2ZvVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfzP7AB-poc_"
      },
      "outputs": [],
      "source": [
        "def load_data(file_name):\n",
        "  with open(file_name, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "  return lines\n",
        "\n",
        "src_lines = load_data('/content/drive/MyDrive/Thesis/NLLB_hi_kn-hi.txt')\n",
        "tgt_lines = load_data('/content/drive/MyDrive/Thesis/NLLB_hi_kn-kn.txt')\n",
        "\n",
        "dataset = pd.DataFrame({'src': src_lines, 'tgt': tgt_lines})\n",
        "\n",
        "dataset = dataset.drop_duplicates().sample(frac=0.02).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt8vu8I57YZL"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load TED2020 dataset from TEDTalk domain\n",
        "\n",
        "The dataset is available in https://opus.nlpl.eu/TED2020/hi&kn/v1/TED2020"
      ],
      "metadata": {
        "id": "br67Lr95Z0pi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JK5gI_b83Sw"
      },
      "outputs": [],
      "source": [
        "unseen_hi = load_data('/content/drive/MyDrive/Thesis/TED2020_hi-kn_hi.txt')\n",
        "unseen_kn = load_data('/content/drive/MyDrive/Thesis/TED2020_hi-kn_kn.txt')\n",
        "\n",
        "unseen_data = pd.DataFrame({'src': unseen_hi, 'tgt': unseen_kn})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_data.shape"
      ],
      "metadata": {
        "id": "ZmIerliWa6JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9oUVM73d7ZA"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.25)\n",
        "train_data, validation_data = train_test_split(train_data, test_size=0.35)\n",
        "\n",
        "small_train, small_test = train_test_split(unseen_data, test_size=0.25)\n",
        "\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "validation_dataset = Dataset.from_pandas(validation_data)\n",
        "test_dataset = Dataset.from_pandas(test_data)\n",
        "\n",
        "small_train = Dataset.from_pandas(small_train)\n",
        "small_test = Dataset.from_pandas(small_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "dys5k5ORKZtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_zZb3WRpz_q"
      },
      "outputs": [],
      "source": [
        "small_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t5gKDEheMFk"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer and model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name = 'google/mt5-base'\n",
        "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwbUYWwrXj6-"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-ahSHhqeKbz"
      },
      "outputs": [],
      "source": [
        "# Process both the original and smaller dataset\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"src\"]\n",
        "    targets = examples[\"tgt\"]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "    return model_inputs\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True, desc=\"Running tokenizer on train dataset\")\n",
        "validation_dataset = validation_dataset.map(preprocess_function, batched=True, desc=\"Running tokenizer on validation dataset\")\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True, desc=\"Running tokenizer on test dataset\")\n",
        "\n",
        "small_train = small_train.map(preprocess_function, batched=True, desc=\"Running tokenizer on small train dataset\")\n",
        "small_test = small_test.map(preprocess_function, batched=True, desc=\"Running tokenizer on small test dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN3hXT1EpezQ"
      },
      "outputs": [],
      "source": [
        "train_dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model for the train and validation set and get the evaluation on test data"
      ],
      "metadata": {
        "id": "RPSo5ebsZ_oo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrpNPMaveC0E"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",  # Save model at the end of each epoch\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=2,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir='./logs',\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=500,\n",
        "    eval_accumulation_steps=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"bleu\",\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Define the BLEU metric\n",
        "bleu_metric = load_metric(\"sacrebleu\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_labels = [[label] for label in decoded_labels]\n",
        "    bleu = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": bleu['score']}\n",
        "\n",
        "# Initialize the trainer for the initial training phase\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model initially\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQYe8t9v-2dn"
      },
      "outputs": [],
      "source": [
        "trainer.train()\n",
        "\n",
        "trainer.save_model(\"./base_large_model.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "n6khNpNwCQj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model_new = AutoModelForSeq2SeqLM.from_pretrained(\"/content/base_large_model.pt\")"
      ],
      "metadata": {
        "id": "O8FZnGOPd3DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiKJQQ01_Utp"
      },
      "outputs": [],
      "source": [
        "# Evaluate on the test set before fine-tuning\n",
        "initial_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(f\"Initial BLEU score on test set: {initial_results['eval_bleu']}\")\n",
        "\n",
        "# Save the model checkpoint after initial training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model for the train and validation set of the TED2020 dataset similarly"
      ],
      "metadata": {
        "id": "KdAEWLXmaSge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set training arguments for fine-tuning\n",
        "\n",
        "fine_tune_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./fine_tune_results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,  # Lower learning rate for fine-tuning\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=2,  # Fewer epochs for fine-tuning\n",
        "    predict_with_generate=True,\n",
        "    logging_dir='./fine_tune_logs',\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=200,\n",
        "    eval_accumulation_steps=2,\n",
        ")\n",
        "\n",
        "# Initialize the trainer for fine-tuning\n",
        "fine_tune_trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=fine_tune_args,\n",
        "    train_dataset=small_train,\n",
        "    eval_dataset=small_test,  # Optionally evaluate on the validation set during fine-tuning\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "fF0aWnEqR_Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fine-tune the model\n",
        "fine_tune_trainer.train()\n",
        "\n",
        "# Evaluate on the test set after fine-tuning\n",
        "final_results = fine_tune_trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(f\"Final BLEU score on test set after fine-tuning: {final_results['eval_bleu']}\")"
      ],
      "metadata": {
        "id": "2fBzeYawBBFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation score and example translation"
      ],
      "metadata": {
        "id": "vNbwfG9_aJEE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyUJK-zey6dh"
      },
      "outputs": [],
      "source": [
        "import sacrebleu\n",
        "# Generate translations and calculate BLEU score for test set\n",
        "def generate_translation(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n",
        "    outputs = model.generate(**inputs).to(device)\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "# Generate translations for the test set\n",
        "refs = [[ex[\"tgt\"]] for ex in test_dataset]\n",
        "preds = [generate_translation(ex[\"src\"]) for ex in test_dataset]\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu = sacrebleu.corpus_bleu(preds, refs)\n",
        "print(f\"Test BLEU score after fine-tuning: {bleu.score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yrZy3TnG7B2"
      },
      "outputs": [],
      "source": [
        "input_text = \"यह एक परीक्षण है।\"\n",
        "result = generate_translation(input_text)\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}